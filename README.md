# FSC Data Discovery Service

Dual-interface data discovery system for dbt projects. Provides both **MCP server** access for AI assistants and **REST API** for programmatic integration with blockchain data models from Bitcoin, Ethereum, and Kairos projects.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MCP Interface     â”‚    â”‚   REST API          â”‚
â”‚ (Claude, AI tools)  â”‚    â”‚ (AI Platform Team)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                            â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  Shared Service     â”‚
          â”‚  (JSON responses)   â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ dbt Artifact Cache  â”‚
          â”‚ (GitHub + Local)    â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites
- [UV](https://docs.astral.sh/uv/getting-started/installation/) with Python 3.10+
- Git

### Installation
```bash
# Clone and setup
git clone <repo-url>
cd data-discovery
uv venv --python 3.10
source .venv/bin/activate
uv sync

# Test the shared service
uv run python -c "from data_discovery.api.service import DataDiscoveryService; print('âœ… Service ready')"
```

## ğŸ”Œ MCP Server Setup

For AI assistants like Claude Desktop:

1. **Add to Claude Desktop** (`claude_desktop_config.json`):
   ```json
   {
     "mcpServers": {
       "data-discovery": {
         "command": "/absolute/path/to/data-discovery/.venv/bin/python",
         "args": ["/absolute/path/to/src/data_discovery/server.py"],
         "env": {
           "DEPLOYMENT_MODE": "desktop"
         }
       }
     }
   }
   ```

2. **Restart Claude Desktop** and start exploring:
   - "Show me all Bitcoin core models"
   - "Get details on ethereum.core.fact_transactions using FQN"
   - "List available blockchain projects"

3. **Debug logs**: `tail -f ~/.cache/data-discovery/claude-server.log`

## ğŸ› ï¸ Available Tools & Endpoints

### Discovery Tools âœ…

| **MCP Tool** | **Future REST Endpoint** | **Description** |
|--------------|---------------------------|-----------------|
| `get_resources` | `GET /resources` | List available dbt projects (Bitcoin, Ethereum, Kairos) |
| `get_models` | `GET /models?filters` | Search models across projects with filtering |
| `get_model_details` | `GET /models/:id` | Comprehensive model metadata and schema |
| `get_description` | `GET /descriptions/:id` | Documentation blocks with expert context |

### Search Capabilities

#### **MCP Parameters** (for AI assistants)
```typescript
// Resource discovery
get_resources(show_details?: boolean, blockchain_filter?: string, category_filter?: string)

// Model search  
get_models(schema?: string, level?: string, resource_id?: string[], limit?: number)

// Model details with multiple search options
get_model_details({
  uniqueId?: string,           // "model.ethereum-models.core__fact_transactions"
  fqn?: string,               // "ethereum.core.fact_transactions" 
  model_name?: string,        // "core__fact_transactions"
  table_name?: string,        // "fact_transactions"
  resource_id?: string[]
})

// Documentation
get_description(doc_name: string, resource_id: string[])
```

#### **REST API Format** (coming soon)
```bash
# Resource discovery
GET /resources?show_details=true&blockchain_filter=ethereum

# Model search
GET /models?schema=core&resource_id=ethereum-models&limit=50

# Model details (multiple search options)
GET /models/model.ethereum-models.core__fact_transactions    # by unique_id
GET /models?fqn=ethereum.core.fact_transactions              # by FQN  
GET /models?model_name=core__fact_transactions               # by model name

# Documentation  
GET /descriptions/__overview__?resource_id=ethereum-models
```

### FQN (Fully Qualified Name) Support ğŸ¯

Perfect for AI platform team integration:

```bash
# Supported FQN formats
ethereum.core.fact_transactions     # database.schema.table
core.fact_transactions              # schema.table

# Smart matching handles dbt conventions
core__fact_transactions â†’ fact_transactions
defi_ethereum_uniswap_v3 â†’ matches "uniswap_v3" table searches
```

## ğŸ”§ Technical Details

### Shared Service Architecture

```python
# Core service class used by both interfaces
from data_discovery.api.service import DataDiscoveryService

service = DataDiscoveryService()

# Returns structured JSON (perfect for REST APIs)
result = await service.get_models(schema="core", limit=10)
# Result: {"models": [...], "total_found": 45, "truncated": false, ...}

# MCP tools convert JSON to TextContent for AI assistants
# REST endpoints return JSON directly
```

### Dependencies
- `mcp` - Model Context Protocol SDK
- `aiohttp` - Async HTTP for GitHub integration  
- `loguru` - Modern logging
- `dataclasses` - Property validation

### File Structure
```
src/data_discovery/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ service.py              # Shared service layer (JSON responses)
â”‚   â””â”€â”€ rest.py                 # REST API endpoints (coming soon)
â”œâ”€â”€ server.py                   # MCP server implementation
â”œâ”€â”€ project_manager.py          # Multi-project artifact management  
â”œâ”€â”€ resources/                  # Project definitions and MCP resources
â”œâ”€â”€ tools/discovery/            # MCP tools (use shared service)
â””â”€â”€ prompts/                    # Tool descriptions and help text
```

## ğŸš« Deprecated Features

### dbt CLI Tools (Disabled)
Previously available, now disabled pending multi-project migration:
- `dbt_list`, `dbt_compile`, `dbt_show`

These may be re-enabled in future versions with multi-project support.

## âš™ï¸ Configuration

### Environment Variables
- `DEPLOYMENT_MODE` - Set to `"desktop"` for Claude Desktop (required)
- `DEBUG` - Enable debug logging (`"true"`/`"false"`)

### Deployment Modes
- **`desktop`** (recommended): Uses `~/.cache/data-discovery/` for cache
- **`local`**: Uses `target/` directory (development only)

## ğŸ› Troubleshooting

### Common Issues

1. **Import Errors**
   ```bash
   # Test core imports
   python -c "from data_discovery.api.service import DataDiscoveryService; print('âœ… OK')"
   ```

2. **MCP Server Issues**
   ```bash
   # Test MCP server directly
   python src/data_discovery/server.py
   ```

3. **Cache Issues**
   ```bash
   # Clear cache and restart
   rm -rf ~/.cache/data-discovery/
   ```

### Debug Logs
```bash
# MCP server logs (Claude Desktop)
tail -f ~/.cache/data-discovery/claude-server.log

# Service-level debugging  
export DEBUG=true
python -c "from loguru import logger; logger.info('Debug enabled')"
```

## ğŸš€ Deployment

### Current: MCP Server
- âœ… Ready for Claude Desktop and MCP clients
- âœ… Multi-project discovery with caching
- âœ… GitHub integration for remote artifacts

### Coming Soon: REST API  
- ğŸš§ FastAPI endpoints using shared service
- ğŸš§ ECS/Fargate deployment for AI platform team
- ğŸš§ Direct JSON responses for vector search integration

---

**Ready for both AI assistant integration (MCP) and programmatic access (REST API)**